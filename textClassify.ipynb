{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### train data\n",
    "train = pd.read_csv('train.csv', header=0, delimiter=\"\\t\", quoting=3)\n",
    "id_train = train['id']\n",
    "sentiment_train = train['sentiment']\n",
    "reviews = train['review']\n",
    "\n",
    "# 简单预处理\n",
    "review_train = []\n",
    "for review in reviews:\n",
    "  # 去掉HTML标签，拿到内容\n",
    "  review_text = BeautifulSoup(review,'lxml').get_text()\n",
    "  # 用正则表达式取出符合规范的部分\n",
    "  # review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "  review_text = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", review_text)     \n",
    "  review_text = re.sub(r\"\\'s\", \" \\'s\", review_text) \n",
    "  review_text = re.sub(r\"\\'ve\", \" \\'ve\", review_text) \n",
    "  review_text = re.sub(r\"n\\'t\", \" n\\'t\", review_text) \n",
    "  review_text = re.sub(r\"\\'re\", \" \\'re\", review_text) \n",
    "  review_text = re.sub(r\"\\'d\", \" \\'d\", review_text) \n",
    "  review_text = re.sub(r\"\\'ll\", \" \\'ll\", review_text) \n",
    "  review_text = re.sub(r\",\", \" , \", review_text) \n",
    "  review_text = re.sub(r\"!\", \" ! \", review_text) \n",
    "  review_text = re.sub(r\"\\(\", \" \\( \", review_text) \n",
    "  review_text = re.sub(r\"\\)\", \" \\) \", review_text) \n",
    "  review_text = re.sub(r\"\\?\", \" \\? \", review_text) \n",
    "  review_text = re.sub(r\"\\s{2,}\", \" \", review_text)\n",
    "  # 小写化所有的词，并转成词list\n",
    "  words = review_text.lower().split()\n",
    "  review_train.append(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### test data  \n",
    "test = pd.read_csv('test.csv', header=0, delimiter=\"\\t\", quoting=3 )\n",
    "id_test = test['id']\n",
    "sentiment_test = test['sentiment']\n",
    "reviews = test['review']\n",
    "\n",
    "# 简单预处理\n",
    "review_test = []\n",
    "for review in reviews:\n",
    "  # 去掉HTML标签，拿到内容\n",
    "  review_text = BeautifulSoup(review,'lxml').get_text()\n",
    "  # 用正则表达式取出符合规范的部分\n",
    "  # review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "  review_text = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", review_text)     \n",
    "  review_text = re.sub(r\"\\'s\", \" \\'s\", review_text) \n",
    "  review_text = re.sub(r\"\\'ve\", \" \\'ve\", review_text) \n",
    "  review_text = re.sub(r\"n\\'t\", \" n\\'t\", review_text) \n",
    "  review_text = re.sub(r\"\\'re\", \" \\'re\", review_text) \n",
    "  review_text = re.sub(r\"\\'d\", \" \\'d\", review_text) \n",
    "  review_text = re.sub(r\"\\'ll\", \" \\'ll\", review_text) \n",
    "  review_text = re.sub(r\",\", \" , \", review_text) \n",
    "  review_text = re.sub(r\"!\", \" ! \", review_text) \n",
    "  review_text = re.sub(r\"\\(\", \" \\( \", review_text) \n",
    "  review_text = re.sub(r\"\\)\", \" \\) \", review_text) \n",
    "  review_text = re.sub(r\"\\?\", \" \\? \", review_text) \n",
    "  review_text = re.sub(r\"\\s{2,}\", \" \", review_text)\n",
    "  # 小写化所有的词，并转成词list\n",
    "  words = review_text.lower().split()\n",
    "  review_test.append(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 参考：http://blog.csdn.net/longxinchen_ml/article/details/50629613\n",
    "tfidf = TFIDF(min_df=2, # 最小支持度为2\n",
    "           max_df=0.5,\n",
    "           max_features=None,\n",
    "           strip_accents='unicode',\n",
    "           analyzer='word',\n",
    "           token_pattern=r'\\w{1,}',\n",
    "           ngram_range=(1, 3),  # 二元文法模型\n",
    "           use_idf=1,\n",
    "           smooth_idf=1,\n",
    "           sublinear_tf=1)\n",
    "           #stop_words = 'english') # 去掉英文停用词\n",
    " \n",
    "# 合并训练和测试集以便进行TFIDF向量化操作\n",
    "data_all = review_train + review_test\n",
    "len_train = len(review_train)\n",
    " \n",
    "tfidf.fit(data_all)\n",
    "data_all = tfidf.transform(data_all)\n",
    "\n",
    "# 恢复成训练集和测试集部分\n",
    "train_x = data_all[:len_train]\n",
    "test_x = data_all[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961242436434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "## LR train\n",
    "lr = LR()\n",
    "lr.fit(train_x[:16000],sentiment_train[:16000])\n",
    "predictions1=lr.predict_proba(train_x[16000:])[:,1]\n",
    "print(metrics.roc_auc_score(sentiment_train[16000:],predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970984962009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "## LR train\n",
    "lr = LR()\n",
    "lr.fit(train_x[:16000]*5,sentiment_train[:16000]*5)\n",
    "predictions1=lr.predict_proba(train_x[16000:])[:,1]\n",
    "print(metrics.roc_auc_score(sentiment_train[16000:],predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972805293765\n"
     ]
    }
   ],
   "source": [
    "## Rd train\n",
    "Rd = Ridge(alpha=.3)\n",
    "\n",
    "Rd.fit(train_x[:16000],sentiment_train[:16000])\n",
    "predictions2=Rd.predict(train_x[16000:])\n",
    "print(metrics.roc_auc_score(sentiment_train[16000:],predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Rd test\n",
    "Rd = Ridge(alpha=.3)\n",
    "\n",
    "Rd.fit(train_x,sentiment_train)\n",
    "t_predictions2=Rd.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB 0.961958316903\n"
     ]
    }
   ],
   "source": [
    "## NB\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "NB = MNB()\n",
    "NB.fit(train_x[:16000]*10,sentiment_train[:16000]*10) #特征数据直接灌进来\n",
    "MNB(alpha=1, class_prior=None, fit_prior=True)\n",
    "predictions3=NB.predict_proba(train_x[16000:])[:,1]\n",
    "print(\"NB\", metrics.roc_auc_score(sentiment_train[16000:],predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NB test\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "NB = MNB()\n",
    "NB.fit(train_x*10,sentiment_train*10) #特征数据直接灌进来\n",
    "MNB(alpha=1, class_prior=None, fit_prior=True)\n",
    "t_predictions3=NB.predict_proba(test_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn 0.894703809769\n"
     ]
    }
   ],
   "source": [
    "## KNN\n",
    "from sklearn import neighbors\n",
    " \n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "#训练数据集\n",
    "knn.fit(train_x[:16000],sentiment_train[:16000])\n",
    "predictions4=knn.predict_proba(train_x[16000:])[:,1]\n",
    "print(\"knn\", metrics.roc_auc_score(sentiment_train[16000:],predictions4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## KNN test\n",
    "from sklearn import neighbors\n",
    " \n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "#训练数据集\n",
    "knn.fit(train_x,sentiment_train)\n",
    "t_predictions4=knn.predict_proba(test_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble 0.975294997513\n"
     ]
    }
   ],
   "source": [
    "predictions=(0.1*predictions1+2*predictions2+0.1*predictions3+0.4*predictions4)\n",
    "print(\"ensemble\", metrics.roc_auc_score(sentiment_train[16000:],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble 0.97531325084\n"
     ]
    }
   ],
   "source": [
    "predictions=(2*predictions2+0.1*predictions3+0.4*predictions4)\n",
    "print(\"ensemble\", metrics.roc_auc_score(sentiment_train[16000:],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble 0.975317001524\n"
     ]
    }
   ],
   "source": [
    "predictions=(2.3*predictions2+0.1*predictions3+0.4*predictions4)\n",
    "print(\"ensemble\", metrics.roc_auc_score(sentiment_train[16000:],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble 0.975366260501\n"
     ]
    }
   ],
   "source": [
    "predictions=(2.3*predictions2+0.3*predictions3+0.4*predictions4)\n",
    "print(\"ensemble\", metrics.roc_auc_score(sentiment_train[16000:],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble 0.973910495188\n"
     ]
    }
   ],
   "source": [
    "predictions=(5*predictions1+0.2*predictions3+0.4*predictions4)\n",
    "print(\"ensemble\", metrics.roc_auc_score(sentiment_train[16000:],predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## write result\n",
    "predictions=(2.3*t_predictions2+0.3*t_predictions3+0.4*t_predictions4)/3\n",
    "data = {'id':id_test,'sentiment':predictions}\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df.to_csv('lc_0717.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
